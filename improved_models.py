# -*- coding: utf-8 -*-
"""Improved_Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AagT44AYJLUrWSwvDpM2ZA5uIWKLwF4p
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error as mse
import tensorflow as tf
from tensorflow import keras
import xgboost as xgb

# plt.rcParams.update({'font.size': 11, 'font.family': ['serif'], 'font.serif': ['Palatino']})

data = pd.read_csv('https://www.dropbox.com/s/hdiyuipgmas8w3h/supercon.csv?dl=1')
critical_temp = data["critical_temp"]
features = data[["mean_atomic_mass", "mean_fie", "mean_atomic_radius", "mean_Density", "mean_ElectronAffinity", "mean_FusionHeat", "mean_ThermalConductivity", "mean_Valence" ]]
(xTrain, xTest, yTrain, yTest) = train_test_split(features, critical_temp, test_size = .4, random_state=17)

model = tf.keras.Sequential()

model.add(tf.keras.Input(shape=(8,)))
model.add(tf.keras.layers.Dense(20, activation = 'selu', kernel_initializer='glorot_normal'))

model.add(tf.keras.layers.Dense(34, activation = 'elu', kernel_initializer='glorot_normal'))
model.add(tf.keras.layers.Dense(24, activation = 'elu', kernel_initializer='glorot_normal'))
model.add(tf.keras.layers.Dense(20, activation = 'relu', kernel_initializer='glorot_normal'))
model.add(tf.keras.layers.Dense(1))


opt = keras.optimizers.Adam(learning_rate=0.01)
model.compile(optimizer=opt, loss='mse')

model.fit(xTrain, yTrain, epochs=18)
predictions = model.predict(xTest)
plt.scatter(yTest, predictions, color = 'red')
plt.xlim([-20,175])
plt.ylim([-20,100])
err = mse(yTest, predictions)
plt.title('mean squared error ' + str(err))
plt.show()

predictions = model.predict(xTest)

reg = xgb.XGBRegressor(max_depth=8, min_child_weight = 0.8, eta = 0.1, gamma=0.1, subsample=1)
reg.fit(xTrain, yTrain)
predictions = reg.predict(xTest)

#Testing
mae_values = []
for k in range(1, 16):
  reg = xgb.XGBRegressor(max_depth=k, booster='gbtree', gamma=0.3, subsample=0.4)
  reg.fit(xTrain, yTrain)
  predictions = reg.predict(xTest)
  mae_values.append(mse(yTest, predictions))

plt.figure(figsize=(10,6))
plt.ylabel("mean squared error")
plt.xlabel("max_depth")
plt.plot(range(1, 16), mae_values)

csfont = {'fontname':'Arial'}
plt.scatter(yTest, predictions, color = 'blue')
plt.xlim([-20,175])
plt.ylim([-20,100])
plt.xlabel('xlabel', **csfont)
err = r2_score(yTest, predictions)
# plt.title('mean squared error ' + str(err))
plt.show()

